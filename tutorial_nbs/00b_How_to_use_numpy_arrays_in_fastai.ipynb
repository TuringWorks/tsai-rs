{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/timeseriesAI/tsai-rs\" target=\"_parent\"><img src=\"https://img.shields.io/badge/tsai--rs-Time%20Series%20AI%20in%20Rust-blue\" alt=\"tsai-rs\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Work with Numpy Arrays in tsai-rs\n",
    "\n",
    "This notebook demonstrates how to use numpy arrays with **tsai-rs** for time series classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "tsai-rs supports:\n",
    "- Univariate and multivariate time series\n",
    "- Labelled (X, y) and unlabelled (X) datasets\n",
    "- Pre-split train/valid data\n",
    "- In-memory and on-disk arrays (np.memmap)\n",
    "- Efficient batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tsai-rs\n",
    "\n",
    "```bash\n",
    "cd crates/tsai_python\n",
    "maturin develop --release\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai_rs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"tsai-rs version: {tsai_rs.version()}\")\n",
    "tsai_rs.my_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UCR dataset with train/test split\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shape: (samples, variables, sequence_length)\n",
    "n_samples = X_train.shape[0]\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Samples: {n_samples}\")\n",
    "print(f\"Variables: {n_vars}\")\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "print(f\"Classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (per sample)\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "\n",
    "print(f\"Before standardization:\")\n",
    "print(f\"  X_train mean: {X_train.mean():.4f}, std: {X_train.std():.4f}\")\n",
    "\n",
    "print(f\"\\nAfter standardization:\")\n",
    "print(f\"  X_train_std mean: {X_train_std.mean():.6f}, std: {X_train_std.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TSDataset objects\n",
    "train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "test_ds = tsai_rs.TSDataset(X_test_std, y_test)\n",
    "\n",
    "print(f\"Train dataset: {train_ds}\")\n",
    "print(f\"Test dataset: {test_ds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model\n",
    "config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "\n",
    "print(f\"Model config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training\n",
    "learner_config = tsai_rs.LearnerConfig(\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    grad_clip=1.0\n",
    ")\n",
    "\n",
    "print(f\"Learner config: {learner_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation\n",
    "X_aug = tsai_rs.add_gaussian_noise(X_train_std, std=0.05, seed=42)\n",
    "X_aug = tsai_rs.mag_scale(X_aug, scale_range=(0.9, 1.1), seed=42)\n",
    "\n",
    "print(f\"Original shape: {X_train_std.shape}\")\n",
    "print(f\"Augmented shape: {X_aug.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentation\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "sample_idx = 0\n",
    "var_idx = 0\n",
    "\n",
    "axes[0].plot(X_train_std[sample_idx, var_idx, :], label='Original')\n",
    "axes[0].set_title('Original Time Series')\n",
    "\n",
    "axes[1].plot(X_aug[sample_idx, var_idx, :], label='Augmented', color='orange')\n",
    "axes[1].set_title('Augmented Time Series')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Different Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different UCR datasets\n",
    "datasets = ['ECG200', 'GunPoint', 'FordA', 'NATOPS']\n",
    "\n",
    "print(f\"{'Dataset':<15} {'Shape':<25} {'Classes':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for dsid in datasets:\n",
    "    try:\n",
    "        X, y, _, _ = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "        n_classes = len(np.unique(y))\n",
    "        print(f\"{dsid:<15} {str(X.shape):<25} {n_classes:<10}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{dsid:<15} Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_pipeline(dsid, model_type='inception'):\n",
    "    \"\"\"Complete time series classification pipeline.\"\"\"\n",
    "    \n",
    "    # 1. Load data\n",
    "    print(f\"Loading {dsid}...\")\n",
    "    X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "    \n",
    "    n_vars = X_train.shape[1]\n",
    "    seq_len = X_train.shape[2]\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    \n",
    "    print(f\"  Shape: {X_train.shape}\")\n",
    "    print(f\"  Variables: {n_vars}, Length: {seq_len}, Classes: {n_classes}\")\n",
    "    \n",
    "    # 2. Preprocess\n",
    "    X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "    X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "    \n",
    "    # 3. Create datasets\n",
    "    train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "    test_ds = tsai_rs.TSDataset(X_test_std, y_test)\n",
    "    \n",
    "    # 4. Configure model\n",
    "    if model_type == 'inception':\n",
    "        config = tsai_rs.InceptionTimePlusConfig(\n",
    "            n_vars=n_vars, seq_len=seq_len, n_classes=n_classes\n",
    "        )\n",
    "    elif model_type == 'resnet':\n",
    "        config = tsai_rs.ResNetPlusConfig(\n",
    "            n_vars=n_vars, seq_len=seq_len, n_classes=n_classes\n",
    "        )\n",
    "    elif model_type == 'tst':\n",
    "        config = tsai_rs.TSTConfig(\n",
    "            n_vars=n_vars, seq_len=seq_len, n_classes=n_classes\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    print(f\"  Model: {config}\")\n",
    "    \n",
    "    # 5. Configure training\n",
    "    learner_config = tsai_rs.LearnerConfig(\n",
    "        lr=1e-3,\n",
    "        weight_decay=0.01,\n",
    "        grad_clip=1.0\n",
    "    )\n",
    "    \n",
    "    print(f\"  Ready for training!\")\n",
    "    \n",
    "    return config, train_ds, test_ds, learner_config\n",
    "\n",
    "# Run pipeline\n",
    "config, train_ds, test_ds, learner_config = classification_pipeline('NATOPS', 'inception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Benefits\n",
    "- Easy numpy array support\n",
    "- Efficient batch processing\n",
    "- Support for univariate and multivariate data\n",
    "- Built-in standardization and augmentation\n",
    "\n",
    "### Pattern\n",
    "```python\n",
    "# Load data\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "# Standardize\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "\n",
    "# Create dataset\n",
    "train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "\n",
    "# Configure model\n",
    "config = tsai_rs.InceptionTimePlusConfig(n_vars, seq_len, n_classes)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference\n",
    "print(\"Numpy Arrays Quick Reference\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n# Load data\")\n",
    "print(\"X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\")\n",
    "print(\"\\n# Standardize\")\n",
    "print(\"X_std = tsai_rs.ts_standardize(X.astype(np.float32), by_sample=True)\")\n",
    "print(\"\\n# Create dataset\")\n",
    "print(\"ds = tsai_rs.TSDataset(X_std, y)\")\n",
    "print(\"\\n# Augment\")\n",
    "print(\"X_aug = tsai_rs.add_gaussian_noise(X, std=0.05, seed=42)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
