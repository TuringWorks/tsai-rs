{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/timeseriesAI/tsai-rs\" target=\"_parent\"><img src=\"https://img.shields.io/badge/tsai--rs-Time%20Series%20AI%20in%20Rust-blue\" alt=\"tsai-rs\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Time Series Classification with tsai-rs\n",
    "\n",
    "This notebook demonstrates time series classification using **tsai-rs**, a Rust implementation of the tsai library with Python bindings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook shows how to:\n",
    "1. Import tsai-rs and load UCR datasets\n",
    "2. Prepare time series data\n",
    "3. Configure models (InceptionTimePlus, PatchTST, etc.)\n",
    "4. Use analysis tools (confusion matrix, metrics)\n",
    "5. Apply transforms (standardization, augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tsai-rs\n",
    "\n",
    "First, build and install the tsai-rs Python bindings:\n",
    "\n",
    "```bash\n",
    "cd crates/tsai_python\n",
    "maturin develop --release\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai_rs\n",
    "import numpy as np\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "# Display version info\n",
    "print(f\"tsai-rs version: {tsai_rs.version()}\")\n",
    "tsai_rs.my_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "### List Available Datasets\n",
    "\n",
    "tsai-rs provides access to UCR Time Series Classification datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List univariate datasets (128 datasets)\n",
    "univariate_datasets = tsai_rs.get_UCR_univariate_list()\n",
    "print(f\"Available univariate datasets ({len(univariate_datasets)}):\")\n",
    "print(univariate_datasets[:20], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List multivariate datasets (30 datasets)\n",
    "multivariate_datasets = tsai_rs.get_UCR_multivariate_list()\n",
    "print(f\"Available multivariate datasets ({len(multivariate_datasets)}):\")\n",
    "print(multivariate_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Load Data\n",
    "\n",
    "Let's load the NATOPS dataset - a multivariate time series classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with train/test split\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "print(f\"Dataset: {dsid}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, load combined data with split indices\n",
    "X, y, splits = tsai_rs.get_UCR_data(dsid, return_split=False)\n",
    "train_idx, test_idx = splits\n",
    "\n",
    "print(f\"Combined X shape: {X.shape}\")\n",
    "print(f\"Combined y shape: {y.shape}\")\n",
    "print(f\"Train indices: {len(train_idx)}, Test indices: {len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format\n",
    "\n",
    "Time series data in tsai-rs uses the format: `(N, V, L)`\n",
    "- **N**: Number of samples\n",
    "- **V**: Number of variables/channels\n",
    "- **L**: Sequence length (time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_vars, seq_len = X_train.shape\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Samples: {n_samples}\")\n",
    "print(f\"Variables: {n_vars}\")\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TSDataset objects for train and test\n",
    "train_ds = tsai_rs.TSDataset(X_train, y_train)\n",
    "test_ds = tsai_rs.TSDataset(X_test, y_test)\n",
    "\n",
    "print(f\"Train dataset: {train_ds}\")\n",
    "print(f\"Test dataset: {test_ds}\")\n",
    "print(f\"Train n_vars: {train_ds.n_vars}, seq_len: {train_ds.seq_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Model\n",
    "\n",
    "tsai-rs provides configurations for state-of-the-art time series models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionTimePlus configuration\n",
    "inception_config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes,\n",
    "    n_blocks=6,\n",
    "    n_filters=32\n",
    ")\n",
    "print(f\"InceptionTimePlus: {inception_config}\")\n",
    "print(f\"Config JSON:\\n{inception_config.to_json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNetPlus configuration\n",
    "resnet_config = tsai_rs.ResNetPlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "print(f\"ResNetPlus: {resnet_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatchTST configuration (Transformer-based)\n",
    "patchtst_config = tsai_rs.PatchTSTConfig.for_classification(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "print(f\"PatchTST: {patchtst_config}\")\n",
    "print(f\"  d_model: {patchtst_config.d_model}\")\n",
    "print(f\"  n_heads: {patchtst_config.n_heads}\")\n",
    "print(f\"  n_layers: {patchtst_config.n_layers}\")\n",
    "print(f\"  n_patches: {patchtst_config.n_patches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TST (Time Series Transformer) configuration\n",
    "tst_config = tsai_rs.TSTConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes,\n",
    "    d_model=128,\n",
    "    n_heads=8,\n",
    "    n_layers=3\n",
    ")\n",
    "print(f\"TST: {tst_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# RNNPlus configuration (LSTM/GRU)\nrnn_config = tsai_rs.RNNPlusConfig(\n    n_vars=n_vars,\n    seq_len=seq_len,\n    n_classes=n_classes,\n    hidden_size=128,\n    n_layers=2,\n    rnn_type='lstm',\n    bidirectional=True\n)\nprint(f\"RNNPlus: {rnn_config}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# MiniRocket configuration\nminirocket_config = tsai_rs.MiniRocketConfig(\n    n_vars=n_vars,\n    seq_len=seq_len,\n    n_classes=n_classes,\n    n_features=10000\n)\nprint(f\"MiniRocket: {minirocket_config}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner configuration\n",
    "learner_config = tsai_rs.LearnerConfig(\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    grad_clip=1.0\n",
    ")\n",
    "print(f\"Learner config: {learner_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-cycle learning rate scheduler\n",
    "n_epochs = 25\n",
    "steps_per_epoch = len(X_train) // 64  # batch_size = 64\n",
    "total_steps = n_epochs * steps_per_epoch\n",
    "\n",
    "scheduler = tsai_rs.OneCycleLR.simple(max_lr=1e-3, total_steps=total_steps)\n",
    "\n",
    "# Get LR schedule for visualization\n",
    "lr_schedule = scheduler.get_lr_schedule(total_steps)\n",
    "print(f\"Total steps: {total_steps}\")\n",
    "print(f\"LR at step 0: {scheduler.get_lr(0):.6f}\")\n",
    "print(f\"LR at step {total_steps//2}: {scheduler.get_lr(total_steps//2):.6f}\")\n",
    "print(f\"LR at step {total_steps-1}: {scheduler.get_lr(total_steps-1):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (by sample)\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "\n",
    "print(f\"Before standardization - mean: {X_train[0].mean():.4f}, std: {X_train[0].std():.4f}\")\n",
    "print(f\"After standardization - mean: {X_train_std[0].mean():.4f}, std: {X_train_std[0].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise\n",
    "X_noisy = tsai_rs.add_gaussian_noise(X_train_std, std=0.1, seed=42)\n",
    "print(f\"Original sample std: {X_train_std[0].std():.4f}\")\n",
    "print(f\"Noisy sample std: {X_noisy[0].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magnitude scaling\n",
    "X_scaled = tsai_rs.mag_scale(X_train_std, scale_range=(0.8, 1.2), seed=42)\n",
    "print(f\"Original max: {X_train_std[0].max():.4f}\")\n",
    "print(f\"Scaled max: {X_scaled[0].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series to Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single univariate time series\n",
    "sample_ts = X_train_std[0, 0, :].astype(np.float32)  # First sample, first variable\n",
    "print(f\"Time series shape: {sample_ts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute GASF (Gramian Angular Summation Field)\n",
    "gasf_image = tsai_rs.compute_gasf(sample_ts)\n",
    "print(f\"GASF image shape: {gasf_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute GADF (Gramian Angular Difference Field)\n",
    "gadf_image = tsai_rs.compute_gadf(sample_ts)\n",
    "print(f\"GADF image shape: {gadf_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Recurrence Plot\n",
    "rp_image = tsai_rs.compute_recurrence_plot(sample_ts, threshold=0.1)\n",
    "print(f\"Recurrence plot shape: {rp_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Confusion Matrix and Metrics\n",
    "\n",
    "Let's simulate some predictions to demonstrate the analysis tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate predictions (in practice, these come from your trained model)\n",
    "np.random.seed(42)\n",
    "y_test_int = y_test.astype(np.int64)\n",
    "\n",
    "# Create \"predictions\" with ~93% accuracy\n",
    "y_pred = y_test_int.copy()\n",
    "n_wrong = int(len(y_test) * 0.07)  # 7% error rate\n",
    "wrong_idx = np.random.choice(len(y_test), n_wrong, replace=False)\n",
    "y_pred[wrong_idx] = np.random.randint(0, n_classes, n_wrong)\n",
    "\n",
    "print(f\"True labels: {y_test_int[:10]}\")\n",
    "print(f\"Predictions: {y_pred[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix using tsai-rs\n",
    "cm = tsai_rs.confusion_matrix(y_pred, y_test_int, n_classes=n_classes)\n",
    "print(f\"Confusion Matrix: {cm}\")\n",
    "print(f\"\\nAccuracy: {cm.accuracy():.4f}\")\n",
    "print(f\"Macro F1: {cm.macro_f1():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class metrics\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for i in range(n_classes):\n",
    "    print(f\"  Class {i}: Precision={cm.precision(i):.4f}, Recall={cm.recall(i):.4f}, F1={cm.f1(i):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix as numpy array\n",
    "cm_matrix = cm.matrix()\n",
    "print(f\"\\nConfusion matrix:\\n{cm_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with sklearn\n",
    "sklearn_accuracy = skm.accuracy_score(y_test_int, y_pred)\n",
    "sklearn_f1 = skm.f1_score(y_test_int, y_pred, average='macro')\n",
    "print(f\"sklearn accuracy: {sklearn_accuracy:.4f}\")\n",
    "print(f\"sklearn macro F1: {sklearn_f1:.4f}\")\n",
    "print(f\"\\ntsai-rs matches sklearn: {np.isclose(cm.accuracy(), sklearn_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Losses Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate per-sample losses and probabilities\n",
    "losses = np.random.rand(len(y_test)).astype(np.float32)\n",
    "losses[wrong_idx] = losses[wrong_idx] + 2.0  # Higher losses for wrong predictions\n",
    "probs = np.random.rand(len(y_test)).astype(np.float32) * 0.5 + 0.5  # 0.5 to 1.0\n",
    "\n",
    "# Find top 10 losses\n",
    "top_10_losses = tsai_rs.top_losses(losses, y_test_int, y_pred, probs, k=10)\n",
    "\n",
    "print(\"Top 10 losses:\")\n",
    "for tl in top_10_losses:\n",
    "    print(f\"  {tl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom train/test split indices\n",
    "n_total = len(X)\n",
    "train_indices, test_indices = tsai_rs.train_test_split_indices(\n",
    "    n_samples=n_total,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {n_total}\")\n",
    "print(f\"Train samples: {len(train_indices)}\")\n",
    "print(f\"Test samples: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine separate splits back together\n",
    "X_combined, y_combined, combined_splits = tsai_rs.combine_split_data(\n",
    "    [X_train, X_test],\n",
    "    [y_train, y_test]\n",
    ")\n",
    "\n",
    "print(f\"Combined X shape: {X_combined.shape}\")\n",
    "print(f\"Combined y shape: {y_combined.shape}\")\n",
    "print(f\"Split 0 (train) size: {len(combined_splits[0])}\")\n",
    "print(f\"Split 1 (test) size: {len(combined_splits[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key features of tsai-rs:\n",
    "\n",
    "1. **Data Loading**: `get_UCR_data`, `get_UCR_univariate_list`, `get_UCR_multivariate_list`\n",
    "2. **Dataset**: `TSDataset` for storing and manipulating time series data\n",
    "3. **Model Configs**: `InceptionTimePlusConfig`, `ResNetPlusConfig`, `PatchTSTConfig`, `TSTConfig`, `RNNPlusConfig`, `MiniRocketConfig`\n",
    "4. **Training**: `LearnerConfig`, `OneCycleLR` scheduler\n",
    "5. **Preprocessing**: `ts_standardize`\n",
    "6. **Augmentation**: `add_gaussian_noise`, `mag_scale`\n",
    "7. **TS-to-Image**: `compute_gasf`, `compute_gadf`, `compute_recurrence_plot`\n",
    "8. **Analysis**: `confusion_matrix`, `top_losses`\n",
    "9. **Utilities**: `train_test_split_indices`, `combine_split_data`\n",
    "\n",
    "For full training with GPU acceleration, use the Rust API directly via the CLI or Rust code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick summary code\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "# Preprocess\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32))\n",
    "X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32))\n",
    "\n",
    "# Configure model\n",
    "n_vars, seq_len = X_train.shape[1], X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "\n",
    "print(f\"Ready to train {config} on {dsid}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}