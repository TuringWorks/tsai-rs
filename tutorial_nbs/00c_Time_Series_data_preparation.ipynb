{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/timeseriesAI/tsai-rs\" target=\"_parent\"><img src=\"https://img.shields.io/badge/tsai--rs-Time%20Series%20AI%20in%20Rust-blue\" alt=\"tsai-rs\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Data Preparation\n",
    "\n",
    "This notebook demonstrates how to prepare your time series data for use with **tsai-rs**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Input Shape\n",
    "\n",
    "tsai-rs requires 3D numpy arrays with shape:\n",
    "\n",
    "- **samples**: Number of time series samples\n",
    "- **variables**: Number of features/channels/dimensions  \n",
    "- **length**: Number of time steps\n",
    "\n",
    "Shape: `(samples, variables, length)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tsai-rs\n",
    "\n",
    "```bash\n",
    "cd crates/tsai_python\n",
    "maturin develop --release\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai_rs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"tsai-rs version: {tsai_rs.version()}\")\n",
    "tsai_rs.my_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCR/UEA Data\n",
    "\n",
    "The easiest case is using UCR/UEA datasets, which are already formatted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a multivariate dataset\n",
    "dsid = 'NATOPS'\n",
    "X, y, splits = tsai_rs.get_UCR_data(dsid, return_split=False)\n",
    "\n",
    "print(f\"Dataset: {dsid}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Splits: train={len(splits[0])}, valid={len(splits[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or get pre-split data\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting 2D Data to 3D\n",
    "\n",
    "If you have univariate time series in 2D format, you need to reshape them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 2D data (samples, length)\n",
    "X_2d = np.random.randn(100, 50)  # 100 samples, 50 time steps\n",
    "print(f\"Original 2D shape: {X_2d.shape}\")\n",
    "\n",
    "# Convert to 3D (samples, 1, length)\n",
    "X_3d = X_2d[:, np.newaxis, :]\n",
    "print(f\"Converted 3D shape: {X_3d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Wide format DataFrame\n",
    "# Each row is a sample, each column is a time step\n",
    "n_samples = 50\n",
    "n_steps = 100\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(n_samples, n_steps),\n",
    "    columns=[f't_{i}' for i in range(n_steps)]\n",
    ")\n",
    "df['label'] = np.random.randint(0, 3, n_samples)\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "y = df['label'].values\n",
    "X = df.drop('label', axis=1).values\n",
    "\n",
    "# Reshape to 3D\n",
    "X = X[:, np.newaxis, :]  # Add channel dimension\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Data from Multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Separate DataFrames for each variable\n",
    "n_samples = 50\n",
    "n_steps = 100\n",
    "n_vars = 3\n",
    "\n",
    "# Create sample DataFrames for each variable\n",
    "dfs = [pd.DataFrame(np.random.randn(n_samples, n_steps)) for _ in range(n_vars)]\n",
    "\n",
    "# Stack into 3D array\n",
    "X = np.stack([df.values for df in dfs], axis=1)\n",
    "\n",
    "print(f\"Number of variables: {n_vars}\")\n",
    "print(f\"X shape: {X.shape}  # (samples, variables, length)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Format to Wide Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Long format DataFrame\n",
    "n_samples = 20\n",
    "n_steps = 50\n",
    "\n",
    "long_df = pd.DataFrame({\n",
    "    'sample_id': np.repeat(range(n_samples), n_steps),\n",
    "    'time_step': np.tile(range(n_steps), n_samples),\n",
    "    'value': np.random.randn(n_samples * n_steps),\n",
    "    'label': np.repeat(np.random.randint(0, 3, n_samples), n_steps)\n",
    "})\n",
    "\n",
    "print(f\"Long format shape: {long_df.shape}\")\n",
    "print(long_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to wide format\n",
    "wide_df = long_df.pivot(index='sample_id', columns='time_step', values='value')\n",
    "\n",
    "# Convert to 3D array\n",
    "X = wide_df.values[:, np.newaxis, :]\n",
    "y = long_df.groupby('sample_id')['label'].first().values\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Variable Length Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sequences have different lengths, you need to pad or truncate\n",
    "sequences = [\n",
    "    np.random.randn(50),\n",
    "    np.random.randn(75),\n",
    "    np.random.randn(60),\n",
    "    np.random.randn(45)\n",
    "]\n",
    "\n",
    "print(\"Original lengths:\", [len(s) for s in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Pad to max length\n",
    "max_len = max(len(s) for s in sequences)\n",
    "\n",
    "def pad_sequence(seq, max_len, pad_value=0):\n",
    "    padded = np.full(max_len, pad_value)\n",
    "    padded[:len(seq)] = seq\n",
    "    return padded\n",
    "\n",
    "X_padded = np.stack([pad_sequence(s, max_len) for s in sequences])\n",
    "X_padded = X_padded[:, np.newaxis, :]  # Add channel dimension\n",
    "\n",
    "print(f\"Padded X shape: {X_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Truncate to min length\n",
    "min_len = min(len(s) for s in sequences)\n",
    "\n",
    "X_truncated = np.stack([s[:min_len] for s in sequences])\n",
    "X_truncated = X_truncated[:, np.newaxis, :]  # Add channel dimension\n",
    "\n",
    "print(f\"Truncated X shape: {X_truncated.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train/Validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "n_samples = 200\n",
    "n_vars = 5\n",
    "seq_len = 100\n",
    "n_classes = 3\n",
    "\n",
    "X = np.random.randn(n_samples, n_vars, seq_len).astype(np.float32)\n",
    "y = np.random.randint(0, n_classes, n_samples)\n",
    "\n",
    "print(f\"Total samples: {n_samples}\")\n",
    "print(f\"X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Train labels: {np.bincount(y_train)}\")\n",
    "print(f\"Test labels: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using with tsai-rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train_std = tsai_rs.ts_standardize(X_train, by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test, by_sample=True)\n",
    "\n",
    "# Create datasets\n",
    "train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "test_ds = tsai_rs.TSDataset(X_test_std, y_test)\n",
    "\n",
    "print(f\"Train dataset: {train_ds}\")\n",
    "print(f\"Test dataset: {test_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "\n",
    "print(f\"Model config: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality(X, y, name=\"Data\"):\n",
    "    \"\"\"Check data quality before training.\"\"\"\n",
    "    print(f\"\\n{name} Quality Check\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Shape\n",
    "    print(f\"Shape: {X.shape}\")\n",
    "    assert len(X.shape) == 3, f\"Expected 3D array, got {len(X.shape)}D\"\n",
    "    \n",
    "    # NaN/Inf\n",
    "    nan_count = np.isnan(X).sum()\n",
    "    inf_count = np.isinf(X).sum()\n",
    "    print(f\"NaN values: {nan_count}\")\n",
    "    print(f\"Inf values: {inf_count}\")\n",
    "    \n",
    "    # Statistics\n",
    "    print(f\"Mean: {X.mean():.4f}, Std: {X.std():.4f}\")\n",
    "    print(f\"Min: {X.min():.4f}, Max: {X.max():.4f}\")\n",
    "    \n",
    "    # Labels\n",
    "    unique_labels = np.unique(y)\n",
    "    print(f\"Labels: {unique_labels}\")\n",
    "    print(f\"Label distribution: {np.bincount(y.astype(int))}\")\n",
    "    \n",
    "    return nan_count == 0 and inf_count == 0\n",
    "\n",
    "# Check your data\n",
    "is_valid = check_data_quality(X_train, y_train, \"Train\")\n",
    "print(f\"\\nData is valid: {is_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Data Requirements\n",
    "1. **Shape**: `(samples, variables, length)`\n",
    "2. **Dtype**: `float32` for X, `int` or `float` for y\n",
    "3. **No NaN/Inf values**\n",
    "\n",
    "### Common Conversions\n",
    "| From | To | Code |\n",
    "|------|-----|------|\n",
    "| 2D (samples, length) | 3D | `X[:, np.newaxis, :]` |\n",
    "| DataFrame (wide) | 3D | `df.values[:, np.newaxis, :]` |\n",
    "| Multiple variables | 3D | `np.stack([v1, v2, v3], axis=1)` |\n",
    "| Variable length | Fixed | Pad or truncate |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference\n",
    "print(\"Data Preparation Quick Reference\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n# Required shape\")\n",
    "print(\"X.shape = (samples, variables, length)\")\n",
    "print(\"\\n# 2D to 3D\")\n",
    "print(\"X_3d = X_2d[:, np.newaxis, :]\")\n",
    "print(\"\\n# Standardize\")\n",
    "print(\"X_std = tsai_rs.ts_standardize(X.astype(np.float32), by_sample=True)\")\n",
    "print(\"\\n# Create dataset\")\n",
    "print(\"ds = tsai_rs.TSDataset(X_std, y)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
