{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROCKET: A New SOTA Classifier with tsai-rs\n",
    "\n",
    "This notebook introduces ROCKET (RandOm Convolutional KErnel Transform) and MiniRocket using tsai-rs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "ROCKET is a time series classification method that achieves state-of-the-art performance with exceptional speed.\n",
    "\n",
    "Key features:\n",
    "- Uses random convolutional kernels to generate features\n",
    "- State-of-the-art accuracy on UCR benchmark\n",
    "- Works with both univariate and multivariate data\n",
    "- Very fast compared to deep learning methods\n",
    "\n",
    "**Authors**: Dempster, A., Petitjean, F., & Webb, G. I. (2019)\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/1910.13051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tsai-rs\n",
    "\n",
    "```bash\n",
    "cd crates/tsai_python\n",
    "maturin develop --release\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai_rs\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegression\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "print(f\"tsai-rs version: {tsai_rs.version()}\")\n",
    "tsai_rs.my_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Let's load a multivariate dataset to demonstrate ROCKET/MiniRocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multivariate dataset\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "print(f\"Dataset: {dsid}\")\n",
    "print(f\"X_train shape: {X_train.shape} (samples, variables, length)\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Classes: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure MiniRocket\n",
    "\n",
    "MiniRocket is an improved version of ROCKET with fewer hyperparameters and faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Variables: {n_vars}\")\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "print(f\"Classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configure MiniRocket\nminirocket_config = tsai_rs.MiniRocketConfig(\n    n_vars=n_vars,\n    seq_len=seq_len,\n    n_classes=n_classes,\n    n_features=10000  # Default number of features\n)\n\nprint(f\"MiniRocket Config: {minirocket_config}\")\nprint(f\"  n_vars: {minirocket_config.n_vars}\")\nprint(f\"  seq_len: {minirocket_config.seq_len}\")\nprint(f\"  n_classes: {minirocket_config.n_classes}\")\nprint(f\"  n_features: {minirocket_config.n_features}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "For ROCKET/MiniRocket, the authors recommend standardizing by sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (by sample, as recommended by ROCKET authors)\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "\n",
    "print(f\"Before standardization:\")\n",
    "print(f\"  Sample 0 mean: {X_train[0].mean():.4f}, std: {X_train[0].std():.4f}\")\n",
    "print(f\"After standardization:\")\n",
    "print(f\"  Sample 0 mean: {X_train_std[0].mean():.4f}, std: {X_train_std[0].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test with several UCR datasets\ndatasets = ['ECG200', 'FordA', 'Wafer', 'GunPoint', 'Coffee']\n\nprint(\"Dataset configurations for MiniRocket:\")\nprint(\"-\" * 70)\n\nfor dsid in datasets:\n    try:\n        X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n        n_vars = X_train.shape[1]\n        seq_len = X_train.shape[2]\n        n_classes = len(np.unique(y_train))\n        \n        config = tsai_rs.MiniRocketConfig(\n            n_vars=n_vars,\n            seq_len=seq_len,\n            n_classes=n_classes,\n            n_features=10000\n        )\n        \n        print(f\"{dsid:20} | train: {X_train.shape[0]:4d} | test: {X_test.shape[0]:4d} | \"\n              f\"vars: {n_vars:2d} | len: {seq_len:4d} | classes: {n_classes}\")\n    except Exception as e:\n        print(f\"{dsid:20} | Error: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate datasets\n",
    "multivariate = ['NATOPS', 'BasicMotions', 'Epilepsy']\n",
    "\n",
    "print(\"Multivariate dataset configurations:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for dsid in multivariate:\n",
    "    try:\n",
    "        X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "        n_vars = X_train.shape[1]\n",
    "        seq_len = X_train.shape[2]\n",
    "        n_classes = len(np.unique(y_train))\n",
    "        \n",
    "        config = tsai_rs.MiniRocketConfig(\n",
    "            n_vars=n_vars,\n",
    "            seq_len=seq_len,\n",
    "            n_classes=n_classes\n",
    "        )\n",
    "        \n",
    "        print(f\"{dsid:20} | vars: {n_vars:2d} | len: {seq_len:4d} | classes: {n_classes} | config: {config}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{dsid:20} | Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation for ROCKET\n",
    "\n",
    "You can apply augmentation before feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset\n",
    "dsid = 'ECG200'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "# Standardize\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "\n",
    "# Apply augmentation (can help with small datasets)\n",
    "X_train_aug1 = tsai_rs.add_gaussian_noise(X_train_std, std=0.05, seed=42)\n",
    "X_train_aug2 = tsai_rs.mag_scale(X_train_std, scale_range=(0.9, 1.1), seed=42)\n",
    "\n",
    "print(f\"Original train shape: {X_train_std.shape}\")\n",
    "print(f\"With augmentation: could concatenate {X_train_std.shape[0] * 3} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate ROCKET predictions (in practice, use actual trained model)\n",
    "np.random.seed(42)\n",
    "y_test_int = y_test.astype(np.int64)\n",
    "n_classes = len(np.unique(y_test))\n",
    "\n",
    "# Simulate high accuracy predictions (ROCKET typically achieves >95%)\n",
    "y_pred = y_test_int.copy()\n",
    "n_wrong = max(1, int(len(y_test) * 0.05))  # 5% error rate\n",
    "wrong_idx = np.random.choice(len(y_test), n_wrong, replace=False)\n",
    "y_pred[wrong_idx] = (y_pred[wrong_idx] + 1) % n_classes\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = tsai_rs.confusion_matrix(y_pred, y_test_int, n_classes=n_classes)\n",
    "print(f\"Confusion Matrix: {cm}\")\n",
    "print(f\"Accuracy: {cm.accuracy():.4f}\")\n",
    "print(f\"Macro F1: {cm.macro_f1():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrix as numpy array\n",
    "cm_matrix = cm.matrix()\n",
    "print(f\"Confusion matrix:\\n{cm_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **MiniRocket Configuration**: `MiniRocketConfig` for both univariate and multivariate data\n",
    "2. **Data Loading**: UCR datasets with `get_UCR_data`\n",
    "3. **Preprocessing**: `ts_standardize` with `by_sample=True` (ROCKET recommendation)\n",
    "4. **Augmentation**: `add_gaussian_noise`, `mag_scale` for data augmentation\n",
    "5. **Analysis**: `confusion_matrix` for evaluation\n",
    "\n",
    "### ROCKET vs MiniRocket\n",
    "\n",
    "| Feature | ROCKET | MiniRocket |\n",
    "|---------|--------|------------|\n",
    "| Kernels | 10,000 | 10,000 |\n",
    "| Kernel sizes | [7, 9, 11] | Fixed |\n",
    "| Features per kernel | 2 | 1 |\n",
    "| Total features | 20,000 | 10,000 |\n",
    "| Speed | Fast | Faster |\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "For full training with tsai-rs CLI:\n",
    "\n",
    "```bash\n",
    "tsai train --model MiniRocket --dataset ECG200 --n-kernels 10000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Complete workflow example\ndsid = 'NATOPS'\nX_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n\n# Preprocess\nX_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\nX_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n\n# Configure\nn_vars, seq_len = X_train.shape[1], X_train.shape[2]\nn_classes = len(np.unique(y_train))\n\nconfig = tsai_rs.MiniRocketConfig(\n    n_vars=n_vars,\n    seq_len=seq_len,\n    n_classes=n_classes,\n    n_features=10000\n)\n\nprint(f\"Ready for MiniRocket training on {dsid}!\")\nprint(f\"Config: {config}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}