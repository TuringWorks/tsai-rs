{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/timeseriesAI/tsai-rs\" target=\"_parent\"><img src=\"https://img.shields.io/badge/tsai--rs-Time%20Series%20AI%20in%20Rust-blue\" alt=\"tsai-rs\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST: A New Transformer for Long-term Time Series Forecasting\n",
    "\n",
    "This notebook demonstrates how to use **PatchTST** for long-term multivariate time series forecasting using **tsai-rs**.\n",
    "\n",
    "Based on:\n",
    "* Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). **A Time Series is Worth 64 Words: Long-term Forecasting with Transformers**. arXiv preprint arXiv:2211.14730.\n",
    "* Presented at ICLR 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is PatchTST?\n",
    "\n",
    "PatchTST is a state-of-the-art transformer architecture for time series forecasting that introduces two key innovations:\n",
    "\n",
    "### 1. Patching\n",
    "Instead of treating each time step as a token, PatchTST groups consecutive time steps into **patches**. This:\n",
    "- Reduces the number of tokens (improving efficiency)\n",
    "- Captures local semantic information\n",
    "- Extends the receptive field of attention\n",
    "\n",
    "### 2. Channel Independence\n",
    "Each variable (channel) is processed independently by the transformer. This:\n",
    "- Reduces model complexity\n",
    "- Improves generalization\n",
    "- Allows the model to focus on temporal patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tsai-rs\n",
    "\n",
    "```bash\n",
    "cd crates/tsai_python\n",
    "maturin develop --release\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai_rs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"tsai-rs version: {tsai_rs.version()}\")\n",
    "tsai_rs.my_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Patching\n",
    "\n",
    "The key insight of PatchTST is to divide the time series into patches, similar to how Vision Transformers divide images into patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how patching works\n",
    "seq_len = 96  # Input sequence length\n",
    "patch_len = 16  # Each patch contains 16 time steps\n",
    "stride = 8  # Patches overlap by 8 time steps\n",
    "\n",
    "# Calculate number of patches\n",
    "n_patches = (seq_len - patch_len) // stride + 1\n",
    "\n",
    "print(f\"Input sequence length: {seq_len}\")\n",
    "print(f\"Patch length: {patch_len}\")\n",
    "print(f\"Stride: {stride}\")\n",
    "print(f\"Number of patches: {n_patches}\")\n",
    "print(f\"\\nThis reduces tokens from {seq_len} to {n_patches} (a {seq_len/n_patches:.1f}x reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize patching\n",
    "np.random.seed(42)\n",
    "time_series = np.cumsum(np.random.randn(seq_len)) + 50\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Original time series\n",
    "axes[0].plot(time_series, 'b-', linewidth=1.5)\n",
    "axes[0].set_title('Original Time Series (96 time steps)')\n",
    "axes[0].set_xlabel('Time Step')\n",
    "\n",
    "# Time series with patches highlighted\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, n_patches))\n",
    "axes[1].plot(time_series, 'gray', alpha=0.3, linewidth=1)\n",
    "\n",
    "for i in range(n_patches):\n",
    "    start = i * stride\n",
    "    end = start + patch_len\n",
    "    patch_indices = np.arange(start, end)\n",
    "    axes[1].plot(patch_indices, time_series[patch_indices], color=colors[i], linewidth=2, label=f'Patch {i+1}')\n",
    "    axes[1].axvspan(start, end-1, alpha=0.1, color=colors[i])\n",
    "\n",
    "axes[1].set_title(f'Patched Time Series ({n_patches} patches, each {patch_len} steps, stride {stride})')\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].legend(loc='upper right', ncol=3, fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PatchTST Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data for configuration\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Dataset: {dsid}\")\n",
    "print(f\"Variables: {n_vars}, Sequence length: {seq_len}, Classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatchTST configuration for classification\n",
    "patchtst_config = tsai_rs.PatchTSTConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes,\n",
    "    patch_len=16,       # Length of each patch\n",
    "    stride=8,           # Stride between patches\n",
    "    d_model=128,        # Model dimension\n",
    "    n_heads=4,          # Number of attention heads\n",
    "    n_layers=3,         # Number of transformer layers\n",
    "    d_ff=256,           # Feed-forward dimension\n",
    "    dropout=0.1         # Dropout rate\n",
    ")\n",
    "\n",
    "print(f\"PatchTST config: {patchtst_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PatchTST for Long-term Forecasting\n",
    "\n",
    "PatchTST was originally designed for forecasting. Here's how to configure it for different forecast horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting configuration\n",
    "context_len = 512   # Look-back window\n",
    "forecast_len = 96   # Prediction horizon\n",
    "n_forecast_vars = 7  # Number of variables to forecast\n",
    "\n",
    "# PatchTST for forecasting\n",
    "patchtst_forecast = tsai_rs.PatchTSTConfig(\n",
    "    n_vars=n_forecast_vars,\n",
    "    seq_len=context_len,\n",
    "    n_classes=forecast_len,  # For forecasting, n_classes = forecast horizon\n",
    "    patch_len=16,\n",
    "    stride=8,\n",
    "    d_model=256,\n",
    "    n_heads=8,\n",
    "    n_layers=6,\n",
    "    d_ff=512,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "print(f\"Forecasting config: {patchtst_forecast}\")\n",
    "print(f\"\\nContext: {context_len} steps -> Forecast: {forecast_len} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Forecast Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different forecast horizons as in the paper\n",
    "horizons = [96, 192, 336, 720]\n",
    "\n",
    "print(f\"{'Horizon':<10} {'Description'}\")\n",
    "print(\"-\" * 40)\n",
    "for h in horizons:\n",
    "    if h == 96:\n",
    "        desc = \"Short-term (1 day for hourly data)\"\n",
    "    elif h == 192:\n",
    "        desc = \"Medium-term (2 days)\"\n",
    "    elif h == 336:\n",
    "        desc = \"Long-term (2 weeks for daily data)\"\n",
    "    else:\n",
    "        desc = \"Very long-term (1 month)\"\n",
    "    print(f\"{h:<10} {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure PatchTST for different horizons\n",
    "configs = {}\n",
    "for horizon in horizons:\n",
    "    configs[horizon] = tsai_rs.PatchTSTConfig(\n",
    "        n_vars=7,\n",
    "        seq_len=512,\n",
    "        n_classes=horizon,\n",
    "        patch_len=16,\n",
    "        stride=8,\n",
    "        d_model=256,\n",
    "        n_heads=8,\n",
    "        n_layers=6\n",
    "    )\n",
    "    print(f\"Horizon {horizon}: {configs[horizon]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PatchTST vs Standard TST\n",
    "\n",
    "Let's compare PatchTST with the standard Time Series Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for comparison\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "# Standard TST\n",
    "tst_config = tsai_rs.TSTConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=3\n",
    ")\n",
    "\n",
    "# PatchTST\n",
    "patchtst_config = tsai_rs.PatchTSTConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes,\n",
    "    patch_len=8,\n",
    "    stride=4,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=3\n",
    ")\n",
    "\n",
    "print(\"Standard TST:\")\n",
    "print(f\"  Tokens per sequence: {seq_len}\")\n",
    "print(f\"  Config: {tst_config}\")\n",
    "\n",
    "n_patches = (seq_len - 8) // 4 + 1\n",
    "print(f\"\\nPatchTST:\")\n",
    "print(f\"  Tokens per sequence: {n_patches}\")\n",
    "print(f\"  Config: {patchtst_config}\")\n",
    "print(f\"  Token reduction: {seq_len/n_patches:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Independence\n",
    "\n",
    "A key feature of PatchTST is that it processes each variable independently, which reduces complexity and improves generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize channel independence concept\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Create sample multivariate time series\n",
    "np.random.seed(42)\n",
    "n_channels = 4\n",
    "length = 96\n",
    "\n",
    "# Generate correlated channels\n",
    "base = np.cumsum(np.random.randn(length))\n",
    "channels = [base + i * 10 + np.random.randn(length) * 2 for i in range(n_channels)]\n",
    "\n",
    "# Left: Traditional approach (all channels together)\n",
    "axes[0, 0].set_title('Traditional: All Channels Together')\n",
    "for i, ch in enumerate(channels):\n",
    "    axes[0, 0].plot(ch, label=f'Channel {i+1}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "\n",
    "# Right: PatchTST approach (channels processed independently)\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "for i in range(n_channels):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    if i == 0:\n",
    "        ax = axes[0, 1]\n",
    "    elif i == 1:\n",
    "        ax = axes[1, 0]\n",
    "    elif i == 2:\n",
    "        ax = axes[1, 1]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    ax.plot(channels[i], color=colors[i])\n",
    "    ax.set_title(f'PatchTST: Channel {i+1} (Independent)')\n",
    "    ax.set_xlabel('Time')\n",
    "\n",
    "plt.suptitle('Channel Independence in PatchTST', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete PatchTST Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete classification pipeline\n",
    "def patchtst_classification_pipeline(dsid):\n",
    "    \"\"\"Complete PatchTST classification pipeline.\"\"\"\n",
    "    \n",
    "    # 1. Load data\n",
    "    print(f\"Loading dataset: {dsid}\")\n",
    "    X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "    \n",
    "    # 2. Get dimensions\n",
    "    n_vars = X_train.shape[1]\n",
    "    seq_len = X_train.shape[2]\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    \n",
    "    print(f\"  Shape: {X_train.shape}\")\n",
    "    print(f\"  Variables: {n_vars}, Length: {seq_len}, Classes: {n_classes}\")\n",
    "    \n",
    "    # 3. Standardize\n",
    "    X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "    X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "    \n",
    "    # 4. Configure PatchTST\n",
    "    # Choose patch_len based on sequence length\n",
    "    patch_len = min(16, seq_len // 4)\n",
    "    stride = patch_len // 2\n",
    "    \n",
    "    config = tsai_rs.PatchTSTConfig(\n",
    "        n_vars=n_vars,\n",
    "        seq_len=seq_len,\n",
    "        n_classes=n_classes,\n",
    "        patch_len=patch_len,\n",
    "        stride=stride,\n",
    "        d_model=128,\n",
    "        n_heads=4,\n",
    "        n_layers=3,\n",
    "        d_ff=256,\n",
    "        dropout=0.1\n",
    "    )\n",
    "    print(f\"  Config: {config}\")\n",
    "    \n",
    "    # 5. Create datasets\n",
    "    train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "    test_ds = tsai_rs.TSDataset(X_test_std, y_test)\n",
    "    \n",
    "    # 6. Configure training\n",
    "    learner_config = tsai_rs.LearnerConfig(\n",
    "        lr=1e-4,\n",
    "        weight_decay=0.01,\n",
    "        grad_clip=1.0\n",
    "    )\n",
    "    \n",
    "    print(f\"  Ready for training!\")\n",
    "    \n",
    "    return config, train_ds, test_ds, learner_config\n",
    "\n",
    "# Run pipeline\n",
    "config, train_ds, test_ds, learner_config = patchtst_classification_pipeline('NATOPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended hyperparameters based on the paper\n",
    "print(\"PatchTST Hyperparameter Recommendations\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "recommendations = {\n",
    "    'patch_len': '16 (default), adjust based on seq_len',\n",
    "    'stride': 'patch_len // 2 (50% overlap)',\n",
    "    'd_model': '128-512 depending on dataset size',\n",
    "    'n_heads': '4-16 (must divide d_model)',\n",
    "    'n_layers': '2-6 depending on complexity',\n",
    "    'd_ff': '2-4x d_model',\n",
    "    'dropout': '0.1-0.3',\n",
    "    'learning_rate': '1e-4 to 1e-3',\n",
    "    'batch_size': '32-128',\n",
    "}\n",
    "\n",
    "for param, rec in recommendations.items():\n",
    "    print(f\"{param:<15}: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use PatchTST\n",
    "\n",
    "| Scenario | Recommendation |\n",
    "|----------|---------------|\n",
    "| Long sequences (>100) | PatchTST (efficient) |\n",
    "| Short sequences (<50) | Standard TST or CNN |\n",
    "| Long-term forecasting | PatchTST |\n",
    "| Many variables | PatchTST (channel independence) |\n",
    "| Limited compute | PatchTST (fewer tokens) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated PatchTST for time series:\n",
    "\n",
    "### Key Innovations\n",
    "1. **Patching**: Reduces tokens and captures local patterns\n",
    "2. **Channel Independence**: Improves efficiency and generalization\n",
    "\n",
    "### Configuration\n",
    "```python\n",
    "config = tsai_rs.PatchTSTConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes,\n",
    "    patch_len=16,\n",
    "    stride=8,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=3\n",
    ")\n",
    "```\n",
    "\n",
    "### Key Benefits\n",
    "- State-of-the-art for long-term forecasting\n",
    "- Efficient attention (fewer tokens)\n",
    "- Better generalization through channel independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference\n",
    "print(\"PatchTST Quick Reference\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n# Configuration\")\n",
    "print(\"config = tsai_rs.PatchTSTConfig(\")\n",
    "print(\"    n_vars=n_vars,\")\n",
    "print(\"    seq_len=seq_len,\")\n",
    "print(\"    n_classes=n_classes,\")\n",
    "print(\"    patch_len=16,     # Patch length\")\n",
    "print(\"    stride=8,         # Stride (overlap)\")\n",
    "print(\"    d_model=128,      # Model dimension\")\n",
    "print(\"    n_heads=4,        # Attention heads\")\n",
    "print(\"    n_layers=3,       # Transformer layers\")\n",
    "print(\")\")\n",
    "\n",
    "print(\"\\n# For forecasting\")\n",
    "print(\"# n_classes = forecast_horizon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
