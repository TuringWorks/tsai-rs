{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/timeseriesAI/tsai-rs\" target=\"_parent\"><img src=\"https://img.shields.io/badge/tsai--rs-Time%20Series%20AI%20in%20Rust-blue\" alt=\"tsai-rs\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class and Multi-Label Time Series Classification\n",
    "\n",
    "This notebook demonstrates multi-class and multi-label classification using **tsai-rs**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Types\n",
    "\n",
    "| Type | Description | Labels per Sample |\n",
    "|------|-------------|-------------------|\n",
    "| Binary | Two classes | 1 (0 or 1) |\n",
    "| Multi-class | Multiple exclusive classes | 1 (one of N) |\n",
    "| Multi-label | Multiple non-exclusive classes | 0 to N |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tsai-rs\n",
    "\n",
    "```bash\n",
    "cd crates/tsai_python\n",
    "maturin develop --release\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai_rs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"tsai-rs version: {tsai_rs.version()}\")\n",
    "tsai_rs.my_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Standard classification where each sample belongs to exactly one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multi-class dataset\n",
    "dsid = 'NATOPS'  # 6 classes\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Dataset: {dsid}\")\n",
    "print(f\"X shape: {X_train.shape}\")\n",
    "print(f\"Classes: {n_classes}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train.astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "\n",
    "# Create datasets\n",
    "train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "test_ds = tsai_rs.TSDataset(X_test_std, y_test)\n",
    "\n",
    "print(f\"Train: {train_ds}\")\n",
    "print(f\"Test: {test_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model for multi-class\n",
    "config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes  # Number of classes\n",
    ")\n",
    "\n",
    "print(f\"Multi-class config: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "A special case of multi-class with exactly 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load binary dataset\n",
    "dsid = 'GunPoint'  # 2 classes\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Dataset: {dsid}\")\n",
    "print(f\"X shape: {X_train.shape}\")\n",
    "print(f\"Classes: {n_classes}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train.astype(int))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model for binary classification\n",
    "config_binary = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=2  # Binary = 2 classes\n",
    ")\n",
    "\n",
    "print(f\"Binary config: {config_binary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Classification\n",
    "\n",
    "Each sample can belong to multiple classes simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic multi-label data\n",
    "n_samples = 200\n",
    "n_vars = 10\n",
    "seq_len = 100\n",
    "n_labels = 5  # 5 possible labels\n",
    "\n",
    "# Generate random time series\n",
    "X = np.random.randn(n_samples, n_vars, seq_len).astype(np.float32)\n",
    "\n",
    "# Generate multi-hot encoded labels (each sample can have multiple labels)\n",
    "# Shape: (n_samples, n_labels)\n",
    "y_multilabel = np.random.randint(0, 2, size=(n_samples, n_labels)).astype(np.float32)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y_multilabel.shape}\")\n",
    "print(f\"\\nFirst 5 samples' labels:\")\n",
    "print(y_multilabel[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze label distribution\n",
    "labels_per_sample = y_multilabel.sum(axis=1)\n",
    "\n",
    "print(f\"Labels per sample distribution:\")\n",
    "print(f\"  Min: {labels_per_sample.min():.0f}\")\n",
    "print(f\"  Max: {labels_per_sample.max():.0f}\")\n",
    "print(f\"  Mean: {labels_per_sample.mean():.2f}\")\n",
    "\n",
    "print(f\"\\nLabel frequency:\")\n",
    "for i in range(n_labels):\n",
    "    count = y_multilabel[:, i].sum()\n",
    "    pct = count / n_samples * 100\n",
    "    print(f\"  Label {i}: {count:.0f} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "split_idx = int(0.8 * n_samples)\n",
    "X_train = X[:split_idx]\n",
    "X_test = X[split_idx:]\n",
    "y_train = y_multilabel[:split_idx]\n",
    "y_test = y_multilabel[split_idx:]\n",
    "\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train_std = tsai_rs.ts_standardize(X_train, by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test, by_sample=True)\n",
    "\n",
    "# Create datasets for multi-label\n",
    "train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "test_ds = tsai_rs.TSDataset(X_test_std, y_test)\n",
    "\n",
    "print(f\"Train dataset: {train_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model for multi-label\n",
    "# For multi-label, n_classes = number of possible labels\n",
    "config_multilabel = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_labels  # Number of labels (not exclusive)\n",
    ")\n",
    "\n",
    "print(f\"Multi-label config: {config_multilabel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Different Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for comparison\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "# Different architectures\n",
    "architectures = {\n",
    "    'InceptionTimePlus': tsai_rs.InceptionTimePlusConfig(\n",
    "        n_vars=n_vars, seq_len=seq_len, n_classes=n_classes\n",
    "    ),\n",
    "    'ResNetPlus': tsai_rs.ResNetPlusConfig(\n",
    "        n_vars=n_vars, seq_len=seq_len, n_classes=n_classes\n",
    "    ),\n",
    "    'TST': tsai_rs.TSTConfig(\n",
    "        n_vars=n_vars, seq_len=seq_len, n_classes=n_classes\n",
    "    ),\n",
    "    'MiniRocket': tsai_rs.MiniRocketConfig(\n",
    "        n_vars=n_vars, seq_len=seq_len, n_classes=n_classes\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"Architectures for {n_classes}-class classification:\")\n",
    "print(\"-\" * 60)\n",
    "for name, config in architectures.items():\n",
    "    print(f\"{name}: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "def compute_class_weights(y):\n",
    "    \"\"\"Compute class weights inversely proportional to frequency.\"\"\"\n",
    "    classes = np.unique(y)\n",
    "    n_samples = len(y)\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    weights = {}\n",
    "    for c in classes:\n",
    "        n_c = (y == c).sum()\n",
    "        weights[c] = n_samples / (n_classes * n_c)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Example with NATOPS\n",
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "class_weights = compute_class_weights(y_train)\n",
    "print(f\"Class weights for {dsid}:\")\n",
    "for c, w in class_weights.items():\n",
    "    print(f\"  Class {c}: {w:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Multi-Class Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_pipeline(dsid):\n",
    "    \"\"\"Complete multi-class classification pipeline.\"\"\"\n",
    "    \n",
    "    # 1. Load data\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Dataset: {dsid}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "    \n",
    "    n_vars = X_train.shape[1]\n",
    "    seq_len = X_train.shape[2]\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    \n",
    "    print(f\"Shape: {X_train.shape}\")\n",
    "    print(f\"Variables: {n_vars}\")\n",
    "    print(f\"Length: {seq_len}\")\n",
    "    print(f\"Classes: {n_classes}\")\n",
    "    \n",
    "    # 2. Preprocess\n",
    "    X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "    X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)\n",
    "    \n",
    "    # 3. Create datasets\n",
    "    train_ds = tsai_rs.TSDataset(X_train_std, y_train)\n",
    "    test_ds = tsai_rs.TSDataset(X_test_std, y_test)\n",
    "    \n",
    "    # 4. Configure model\n",
    "    config = tsai_rs.InceptionTimePlusConfig(\n",
    "        n_vars=n_vars,\n",
    "        seq_len=seq_len,\n",
    "        n_classes=n_classes\n",
    "    )\n",
    "    \n",
    "    # 5. Configure training\n",
    "    learner_config = tsai_rs.LearnerConfig(\n",
    "        lr=1e-3,\n",
    "        weight_decay=0.01,\n",
    "        grad_clip=1.0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel: {config}\")\n",
    "    print(f\"Ready for training!\")\n",
    "    \n",
    "    return config, train_ds, test_ds, learner_config\n",
    "\n",
    "# Run pipeline on different datasets\n",
    "for dsid in ['ECG200', 'GunPoint', 'NATOPS']:\n",
    "    config, train_ds, test_ds, learner_config = multiclass_pipeline(dsid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Classification Types\n",
    "\n",
    "| Type | y Shape | Loss | Output |\n",
    "|------|---------|------|--------|\n",
    "| Binary | (n,) | CrossEntropy | 2 classes |\n",
    "| Multi-class | (n,) | CrossEntropy | N classes |\n",
    "| Multi-label | (n, K) | BCEWithLogits | K labels |\n",
    "\n",
    "### Key Points\n",
    "1. **Multi-class**: Each sample has exactly one label\n",
    "2. **Multi-label**: Each sample can have 0 to K labels\n",
    "3. **Class imbalance**: Use weighted loss or oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference\n",
    "print(\"Classification Quick Reference\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n# Multi-class (exclusive labels)\")\n",
    "print(\"y = np.array([0, 1, 2, 0, 1])  # One label per sample\")\n",
    "print(\"config = tsai_rs.InceptionTimePlusConfig(n_vars, seq_len, n_classes=3)\")\n",
    "print(\"\\n# Multi-label (non-exclusive)\")\n",
    "print(\"y = np.array([[1,0,1], [0,1,0]])  # Multi-hot encoding\")\n",
    "print(\"config = tsai_rs.InceptionTimePlusConfig(n_vars, seq_len, n_classes=3)\")\n",
    "print(\"# Use BCEWithLogitsLoss for multi-label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
