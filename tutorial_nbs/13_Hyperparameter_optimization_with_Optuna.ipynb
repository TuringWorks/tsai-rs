{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/timeseriesAI/tsai-rs\" target=\"_parent\"><img src=\"https://img.shields.io/badge/tsai--rs-Time%20Series%20AI%20in%20Rust-blue\" alt=\"tsai-rs\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization with Optuna\n",
    "\n",
    "This notebook demonstrates how to optimize hyperparameters for time series models using **tsai-rs** with Optuna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "Hyperparameter optimization helps you find the best configuration for your model.\n",
    "\n",
    "Optuna provides:\n",
    "1. **Efficient search**: Bayesian optimization finds good params faster than grid search\n",
    "2. **Pruning**: Early stopping of unpromising trials\n",
    "3. **Visualization**: Understand parameter importance\n",
    "4. **Parallelization**: Run multiple trials concurrently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "```bash\n",
    "pip install optuna\n",
    "cd crates/tsai_python\n",
    "maturin develop --release\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai_rs\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "print(f\"tsai-rs version: {tsai_rs.version()}\")\n",
    "print(f\"optuna version: {optuna.__version__}\")\n",
    "tsai_rs.my_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsid = 'NATOPS'\n",
    "X_train, y_train, X_test, y_test = tsai_rs.get_UCR_data(dsid, return_split=True)\n",
    "\n",
    "n_vars = X_train.shape[1]\n",
    "seq_len = X_train.shape[2]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Dataset: {dsid}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"Variables: {n_vars}, Sequence length: {seq_len}, Classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "X_train_std = tsai_rs.ts_standardize(X_train.astype(np.float32), by_sample=True)\n",
    "X_test_std = tsai_rs.ts_standardize(X_test.astype(np.float32), by_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline configuration with default parameters\n",
    "baseline_config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "\n",
    "baseline_learner = tsai_rs.LearnerConfig(\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    grad_clip=1.0\n",
    ")\n",
    "\n",
    "print(f\"Baseline model config: {baseline_config}\")\n",
    "print(f\"Baseline learner config: {baseline_learner}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Objective Function\n",
    "\n",
    "The objective function defines what Optuna should optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_training(config_params):\n",
    "    \"\"\"Simulate training with given hyperparameters.\n",
    "    \n",
    "    In a real scenario, this would train the model and return validation accuracy.\n",
    "    \"\"\"\n",
    "    # Simulate that certain parameter combinations work better\n",
    "    lr = config_params['lr']\n",
    "    weight_decay = config_params['weight_decay']\n",
    "    depth = config_params.get('depth', 6)\n",
    "    nf = config_params.get('nf', 32)\n",
    "    \n",
    "    # Simulate accuracy based on hyperparameters\n",
    "    # (In reality, you would train and evaluate)\n",
    "    base_acc = 0.7\n",
    "    \n",
    "    # Learning rate effect (optimal around 1e-3)\n",
    "    lr_effect = -np.abs(np.log10(lr) + 3) * 0.05\n",
    "    \n",
    "    # Weight decay effect (optimal around 0.01)\n",
    "    wd_effect = -np.abs(np.log10(weight_decay + 1e-10) + 2) * 0.02\n",
    "    \n",
    "    # Depth effect (optimal around 6)\n",
    "    depth_effect = -np.abs(depth - 6) * 0.02\n",
    "    \n",
    "    # Number of filters effect (more is generally better up to a point)\n",
    "    nf_effect = 0.1 * np.log(nf / 32)\n",
    "    \n",
    "    # Add some noise\n",
    "    noise = np.random.normal(0, 0.02)\n",
    "    \n",
    "    accuracy = base_acc + lr_effect + wd_effect + depth_effect + nf_effect + noise\n",
    "    accuracy = np.clip(accuracy, 0, 1)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization.\"\"\"\n",
    "    \n",
    "    # Define search space\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-1, log=True)\n",
    "    nf = trial.suggest_categorical('nf', [16, 32, 64, 96])\n",
    "    depth = trial.suggest_int('depth', 3, 9, step=3)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5, step=0.1)\n",
    "    \n",
    "    # Create configuration\n",
    "    config_params = {\n",
    "        'lr': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'nf': nf,\n",
    "        'depth': depth,\n",
    "        'dropout': dropout,\n",
    "    }\n",
    "    \n",
    "    # Simulate training and get accuracy\n",
    "    accuracy = simulate_training(config_params)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # Maximize accuracy\n",
    "    study_name='tsai_rs_hpo'\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "n_trials = 50\n",
    "print(f\"Running {n_trials} trials...\")\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best trial\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value (accuracy): {study.best_value:.4f}\")\n",
    "print(f\"  Parameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study statistics\n",
    "print(\"\\nStudy statistics:\")\n",
    "print(f\"  Number of finished trials: {len(study.trials)}\")\n",
    "print(f\"  Best trial number: {study.best_trial.number}\")\n",
    "\n",
    "# Get trial history\n",
    "trial_values = [t.value for t in study.trials if t.value is not None]\n",
    "print(f\"  Mean accuracy: {np.mean(trial_values):.4f}\")\n",
    "print(f\"  Std accuracy: {np.std(trial_values):.4f}\")\n",
    "print(f\"  Min accuracy: {np.min(trial_values):.4f}\")\n",
    "print(f\"  Max accuracy: {np.max(trial_values):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot optimization history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Trial values over time\n",
    "ax1 = axes[0]\n",
    "trial_numbers = range(len(trial_values))\n",
    "ax1.scatter(trial_numbers, trial_values, alpha=0.6, label='Trial value')\n",
    "\n",
    "# Running best\n",
    "running_best = [max(trial_values[:i+1]) for i in range(len(trial_values))]\n",
    "ax1.plot(trial_numbers, running_best, 'r-', linewidth=2, label='Best so far')\n",
    "\n",
    "ax1.set_xlabel('Trial')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Optimization History')\n",
    "ax1.legend()\n",
    "\n",
    "# Parameter distributions for top trials\n",
    "ax2 = axes[1]\n",
    "top_n = 10\n",
    "sorted_trials = sorted(study.trials, key=lambda t: t.value if t.value else 0, reverse=True)[:top_n]\n",
    "top_lrs = [t.params['lr'] for t in sorted_trials]\n",
    "top_values = [t.value for t in sorted_trials]\n",
    "\n",
    "ax2.scatter(top_lrs, top_values, s=100, c=range(top_n), cmap='viridis')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Learning Rate')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title(f'Top {top_n} Trials by Learning Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate parameter importance\n",
    "try:\n",
    "    importances = optuna.importance.get_param_importances(study)\n",
    "    \n",
    "    print(\"Parameter importances:\")\n",
    "    print(\"-\" * 40)\n",
    "    for param, importance in importances.items():\n",
    "        print(f\"  {param}: {importance:.4f}\")\n",
    "        \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    params = list(importances.keys())\n",
    "    values = list(importances.values())\n",
    "    \n",
    "    ax.barh(params, values, color='steelblue', edgecolor='black')\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_title('Hyperparameter Importance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not compute importances: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Optimized Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tsai-rs configuration with best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "optimized_model_config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes,\n",
    "    # Additional params would go here based on what the config supports\n",
    ")\n",
    "\n",
    "optimized_learner_config = tsai_rs.LearnerConfig(\n",
    "    lr=best_params['lr'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    grad_clip=1.0\n",
    ")\n",
    "\n",
    "print(\"Optimized configuration:\")\n",
    "print(f\"  Model: {optimized_model_config}\")\n",
    "print(f\"  Learner: {optimized_learner_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Objective Optimization\n",
    "\n",
    "Sometimes you want to optimize multiple objectives (e.g., accuracy and speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_objective(trial: optuna.Trial):\n",
    "    \"\"\"Multi-objective optimization: accuracy and inference speed.\"\"\"\n",
    "    \n",
    "    # Search space\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    nf = trial.suggest_categorical('nf', [16, 32, 64, 96])\n",
    "    depth = trial.suggest_int('depth', 3, 9, step=3)\n",
    "    \n",
    "    # Simulate accuracy\n",
    "    accuracy = simulate_training({'lr': lr, 'weight_decay': 0.01, 'nf': nf, 'depth': depth})\n",
    "    \n",
    "    # Simulate inference speed (inversely related to model size)\n",
    "    # Larger models are slower\n",
    "    model_size = nf * depth\n",
    "    inference_speed = 1.0 / (1 + model_size / 100)  # Normalized speed\n",
    "    \n",
    "    return accuracy, inference_speed\n",
    "\n",
    "# Create multi-objective study\n",
    "multi_study = optuna.create_study(\n",
    "    directions=['maximize', 'maximize'],  # Maximize both\n",
    "    study_name='tsai_rs_multi_objective'\n",
    ")\n",
    "\n",
    "print(\"Running multi-objective optimization...\")\n",
    "multi_study.optimize(multi_objective, n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pareto front\n",
    "print(\"\\nPareto optimal trials:\")\n",
    "for trial in multi_study.best_trials:\n",
    "    print(f\"  Trial {trial.number}:\")\n",
    "    print(f\"    Accuracy: {trial.values[0]:.4f}\")\n",
    "    print(f\"    Speed: {trial.values[1]:.4f}\")\n",
    "    print(f\"    Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def architecture_objective(trial: optuna.Trial):\n",
    "    \"\"\"Search across different architectures.\"\"\"\n",
    "    \n",
    "    # Architecture selection\n",
    "    arch = trial.suggest_categorical('architecture', [\n",
    "        'InceptionTimePlus', 'ResNetPlus', 'TST', 'MiniRocket'\n",
    "    ])\n",
    "    \n",
    "    # Common hyperparameters\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    # Simulate different base accuracies for different architectures\n",
    "    base_accuracies = {\n",
    "        'InceptionTimePlus': 0.85,\n",
    "        'ResNetPlus': 0.82,\n",
    "        'TST': 0.88,\n",
    "        'MiniRocket': 0.84,\n",
    "    }\n",
    "    \n",
    "    base_acc = base_accuracies[arch]\n",
    "    lr_effect = -np.abs(np.log10(lr) + 3) * 0.05\n",
    "    noise = np.random.normal(0, 0.02)\n",
    "    \n",
    "    accuracy = base_acc + lr_effect + noise\n",
    "    return np.clip(accuracy, 0, 1)\n",
    "\n",
    "# Run architecture search\n",
    "arch_study = optuna.create_study(direction='maximize', study_name='arch_search')\n",
    "arch_study.optimize(architecture_objective, n_trials=40, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nBest architecture: {arch_study.best_params['architecture']}\")\n",
    "print(f\"Best accuracy: {arch_study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated hyperparameter optimization with Optuna:\n",
    "\n",
    "### Key Concepts\n",
    "1. **Define search space**: Use `trial.suggest_*` methods\n",
    "2. **Objective function**: Returns the metric to optimize\n",
    "3. **Study**: Manages the optimization process\n",
    "4. **Analysis**: Understand parameter importance\n",
    "\n",
    "### Optuna Features Used\n",
    "- `suggest_float`: Continuous parameters (log scale optional)\n",
    "- `suggest_categorical`: Discrete choices\n",
    "- `suggest_int`: Integer parameters\n",
    "- Multi-objective optimization\n",
    "- Parameter importance analysis\n",
    "\n",
    "### tsai-rs Integration\n",
    "```python\n",
    "# Use best params in tsai-rs config\n",
    "config = tsai_rs.InceptionTimePlusConfig(\n",
    "    n_vars=n_vars,\n",
    "    seq_len=seq_len,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "\n",
    "learner_config = tsai_rs.LearnerConfig(\n",
    "    lr=study.best_params['lr'],\n",
    "    weight_decay=study.best_params['weight_decay']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference\n",
    "print(\"Optuna + tsai-rs Quick Reference\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\n# Define objective\")\n",
    "print(\"def objective(trial):\")\n",
    "print(\"    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\")\n",
    "print(\"    return accuracy\")\n",
    "print(\"\\n# Create and run study\")\n",
    "print(\"study = optuna.create_study(direction='maximize')\")\n",
    "print(\"study.optimize(objective, n_trials=100)\")\n",
    "print(\"\\n# Get best parameters\")\n",
    "print(\"best_params = study.best_params\")\n",
    "print(\"best_value = study.best_value\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
